{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree是一种分类和回归算法，本质上是if-then的集合，也可以认为是在特征空间与类空间上的条件概率分布。\n",
    "> 以分类问题为例，训练tree时需要输入data和label，输出预测label。\n",
    "\n",
    "decision tree的一个重要特点是**互斥且完备**，每个样本只能被一条路径覆盖。\n",
    "\n",
    "算法主要分为3步：\n",
    "- 特征选择\n",
    "- 生成决策树\n",
    "- 剪枝（泛化降低过拟合）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集是mnist图片数据集，label_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humility</th>\n",
       "      <th>outlook</th>\n",
       "      <th>play</th>\n",
       "      <th>temp</th>\n",
       "      <th>windy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>hot</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>hot</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>hot</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "      <td>cool</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>normal</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>normal</td>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>normal</td>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>high</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>normal</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>hot</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>high</td>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   humility   outlook play  temp  windy\n",
       "0      high     sunny   no   hot  false\n",
       "1      high     sunny   no   hot   true\n",
       "2      high  overcast  yes   hot  false\n",
       "3      high     rainy  yes  mild  false\n",
       "4    normal     rainy  yes  cool  false\n",
       "5    normal     rainy   no  cool   true\n",
       "6    normal  overcast  yes  cool   true\n",
       "7      high     sunny   no  mild  false\n",
       "8    normal     sunny  yes  cool  false\n",
       "9    normal     rainy  yes  mild  false\n",
       "10   normal     sunny  yes  mild   true\n",
       "11     high  overcast  yes  mild   true\n",
       "12   normal  overcast  yes   hot  false\n",
       "13     high     rainy   no  mild   true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入数据集\n",
    "df = pd.read_csv('example_data.csv', dtype={'windy':'str'})\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# X_test = np.array(X_test)\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 特征选择\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 选取对训练数据**具有分类能力**的特征。\n",
    "\n",
    "如果一个特征的分类结果与随机分类的结果没什么差别，那么这个特征就没什么分类能力，我们就可以不使用这些特征进行分类。\n",
    "\n",
    "对于特征选择的准则可以用Information gain（信息增益）。它是通过entropy（熵）来计算的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 信息增益（Information gain）\n",
    "\n",
    "### 1.1.1 熵与条件熵\n",
    "#### 熵\n",
    "> 信息论中，熵entropy是用来描述随机变量不确定性大小的度量，熵越大，不确定性就越大。\n",
    "- 不确定性就是随机性，熵大说明这个信息没什么价值，因为不确定性太多。\n",
    "\n",
    "熵的公式：对于随机一个离散随机变量$X$，他的熵是\n",
    "$$H(X) = -\\sum^{n}_{i=1}p_i\\log p_i$$\n",
    "\n",
    "#### 条件熵\n",
    "\n",
    "> 条件熵是已知随机变量$X$的条件下，随机变量$Y$的不确定性。\n",
    "\n",
    "公式：$$H(Y|X)=\\sum^{n}_{i=1}p_i H(Y|X=x_i)$$\n",
    "\n",
    "- 其中$i$表示特征$A$不同的取值\n",
    "- 可以看出条件熵的公式很像$H(Y|X)$的期望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 信息增益\n",
    "\n",
    "> 信息增益表示得知特征X的信息而使得Y的信息的不确定性减少程度。简单来说就是，知道了X的信息对认识Y是否更有帮助。\n",
    "- 由此可见，信息增益越大，这个特征X就越有用。\n",
    "\n",
    "公式：特征A对训练集D的信息增益为D的经验熵H(D)与特征A给定条件下的经验条件特征熵之差$$g(D,A) = H(D)-H(D|A)$$\n",
    "- 经验熵empirical entropy是指公式中的概率由极大似然估计得到的。\n",
    "    - 在决策树中MLE $p(x_i) = \\frac{C_i}{D}$，即该特征的样本点在数据集中出现的次数\n",
    "- 在决策树中，**H(D)是整个数据集的不确定性，H(D|A)是知道了A后数据集D的不确定性**，那这个差越大说明特征A对不确定性的降低越多，就越有用。\n",
    "\n",
    "\n",
    "#### 信息增益算法\n",
    "根据信息增益准则选特征的方法就是计算每个特征$A_i$的$g(D,A_i)$，选最大的那个特征。\n",
    "- input：训练数据集D与特征A\n",
    "- output：特征A对训练数据集D的$g(D,A)$\n",
    "1. 计算$H(D)$\n",
    "    $$H(D) =  -\\sum_{k=1}^K\\frac{|C_k|}{|D|}\\log_2\\frac{|C_k|}{|D|}$$\n",
    "2. 计算每个特征$A_i$的$H(D|A_i)$\n",
    "    $$H(D|A) = \\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i) = -\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{k=1}^K\\frac{|D_{ik}|}{|D_i|}\\log_2\\frac{|D_{ik}|}{|D_i|}$$\n",
    "3. 计算每个$g(D,A_i)$\n",
    "    $$g(D,A) = H(D)-H(D|A)$$\n",
    "\n",
    "### 1.1.3 信息增益比（Information Gain ratio）\n",
    "> 信息增益可能存在偏向**特征选择较多的特征**的问题，比如，如果一个特征的每个可能值都会对应一个唯一的数据点，那这个特征可以完美的划分数据，因此他的IG会是最大的。\n",
    "\n",
    "信息增益比可以对这一问题进行校正：\n",
    "\n",
    "$$g_R(D,A) = \\frac{g(D,A)}{H_A(D)}$$\n",
    "其中分子是针对特征A的熵。原本的是针对D的分类的熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(D), entropy实现\n",
    "def entropy(labels:np.ndarray):\n",
    "    '''\n",
    "    计算熵: H(D)\n",
    "    train_label: 数据集标签1D array,\n",
    "    '''\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    prob_array = counts/counts.sum()\n",
    "    return -np.sum(prob_array*np.log2(prob_array))\n",
    "\n",
    "# H(D|A_i)，条件熵实现\n",
    "def cond_entropy(train_data, labels):\n",
    "    '''\n",
    "    计算条件熵: H(D|A),这里的A是某一个特征\n",
    "    train_data: 某个特征列的数据集 1D，不是整个数据集\n",
    "    labels: 标签array 1D\n",
    "    '''\n",
    "    labels_len = len(labels)\n",
    "    unique_features = np.unique(train_data) # 唯一的特征\n",
    "    ## 1. 用for循环计算该特征下每个特征的 p_i*H(D_i)\n",
    "    cond_entropy = 0\n",
    "    for feature in unique_features:\n",
    "        subset = labels[train_data == feature] #取数据集中特征为该值的标签\n",
    "        cond_entropy += (len(subset)/labels_len * entropy(subset))\n",
    "    \n",
    "    return cond_entropy \n",
    "\n",
    "\n",
    "# g(D,A)实现\n",
    "def calc_IG(feature_col, feature):\n",
    "    '''\n",
    "    计算信息增益: G(D,A)\n",
    "    '''\n",
    "    return entropy(feature) - cond_entropy(feature_col, feature)\n",
    "    \n",
    "# g_R(D,A)实现\n",
    "def calc_IGR(feature_col, feature):\n",
    "    '''\n",
    "    计算信息增益比: G_R(D,A)\n",
    "    '''\n",
    "    return calc_IG(feature_col,feature)/entropy(feature_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集D的熵0.9709505944546686\n",
      "第一列特征的条件熵0.5509775004326937\n",
      "第一列的IG: 0.4199730940219749\n",
      "第一列的IGR: 0.4325380677663126\n"
     ]
    }
   ],
   "source": [
    "D = np.array([\n",
    "    [1, 1, 'Yes'],\n",
    "    [1, 0, 'Yes'],\n",
    "    [0, 1, 'No'],\n",
    "    [0, 0, 'No'],\n",
    "    [1, 0, 'No']\n",
    "])\n",
    "print(f'数据集D的熵{entropy(D[:,2])}')\n",
    "print(f'第一列特征的条件熵{cond_entropy(D[:,0],D[:,2])}')\n",
    "print(f'第一列的IG: {calc_IG(D[:,0],D[:,2])}')\n",
    "print(f'第一列的IGR: {calc_IGR(D[:,0],D[:,2])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 决策树生成\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树生成有多种变形，主要区别在于分类结点的特征选取标准。比较经典的生成算法有：\n",
    "- ID3\n",
    "- C4.5\n",
    "- CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 ID3算法\n",
    "> 以Information Gain为准则选取特征，递归的构建决策树。\n",
    "\n",
    "具体步骤：\n",
    "input：数据集D，特征集A，阈值 $\\epsilon$\n",
    "output: 决策树T\n",
    "1. if D中的所有实例都属于同一类 $C_k$ -> T为单结点🌲，并将$C_k$作为该node的类标记，返回T\n",
    "2. if $A = \\emptyset$ -> T为单结点tree,数据集中最大的类$C_k$作为该node的类标记，返回T\n",
    "3. else -> 计算A中各特征对D的**Information Gain**，记录最大的特征$A_g$\n",
    "4. if $A_g < \\epsilon$ -> T为单结点树，将D中实例最大的类最为类标记，返回T\n",
    "5. else -> 对 $A_g$的每个值 $a_i$依次将D分割为若干非空子集D_i,将D_i中最大的类作为类标记，构建子节点，得到T并返回\n",
    "6. 对每个子节点，以D_i为训练集，A-{A_g}为特征及，递归调用1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24674981977443933,\n",
       " 'outlook',\n",
       " {'sunny':    humility outlook play  temp  windy\n",
       "  0      high   sunny   no   hot  false\n",
       "  1      high   sunny   no   hot   true\n",
       "  7      high   sunny   no  mild  false\n",
       "  8    normal   sunny  yes  cool  false\n",
       "  10   normal   sunny  yes  mild   true,\n",
       "  'overcast':    humility   outlook play  temp  windy\n",
       "  2      high  overcast  yes   hot  false\n",
       "  6    normal  overcast  yes  cool   true\n",
       "  11     high  overcast  yes  mild   true\n",
       "  12   normal  overcast  yes   hot  false,\n",
       "  'rainy':    humility outlook play  temp  windy\n",
       "  3      high   rainy  yes  mild  false\n",
       "  4    normal   rainy  yes  cool  false\n",
       "  5    normal   rainy   no  cool   true\n",
       "  9    normal   rainy  yes  mild  false\n",
       "  13     high   rainy   no  mild   true})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dataframe(data, col):\n",
    "    unique_values = data[col].unique()\n",
    "    result_dict = {elem: pd.DataFrame for elem in unique_values}\n",
    "    for key in result_dict.keys():\n",
    "        result_dict[key] = data[:][data[col] == key]\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def choose_best_col(df, label):\n",
    "    H_D = entropy(df[label].tolist())\n",
    "    cols = [col for col in df.columns if col not in [label]]\n",
    "    max_value, best_col = -999, None\n",
    "    max_splited = None\n",
    "    for col in cols:\n",
    "        splited_set = split_dataframe(df, col)\n",
    "        H_DA = 0\n",
    "        for subset_col, subset in splited_set.items():\n",
    "            H_Di = entropy(subset[label].tolist())\n",
    "            H_DA += len(subset)/len(df) * H_Di\n",
    "        IG = H_D - H_DA\n",
    "\n",
    "        if IG > max_value:\n",
    "            max_value, best_col = IG, col\n",
    "            max_splited = splited_set\n",
    "    return max_value, best_col, max_splited\n",
    "\n",
    "choose_best_col(df, 'play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    ''' \n",
    "    ID3的node\n",
    "    '''\n",
    "    def __init__(self, name):\n",
    "        self.name = name        # 结点名\n",
    "        self.connections = {}   # 结点的child\n",
    "    \n",
    "    def connect(self, label, node):\n",
    "        ''' \n",
    "        给当前结点增加child node\n",
    "        '''\n",
    "        self.connections[label] = node\n",
    "\n",
    "class ID3Tree:\n",
    "    ''' \n",
    "    生成一个ID3的决策树\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data, label):\n",
    "        self.columns = data.columns # 返回pd的col name\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.root = Node('Root')\n",
    "    \n",
    "    def print_tree(self, node, tabs):\n",
    "        ''' \n",
    "        打印tree的结构\n",
    "        '''\n",
    "        print(tabs + node.name)\n",
    "        for connection, child_node in node.connections.items():\n",
    "            print(tabs + '\\t' + '(' + connection + ')')\n",
    "            self.print_tree(child_node, tabs + '\\t\\t')\n",
    "\n",
    "    def construct(self, parent_node, parent_connection_label, input_data, columns):\n",
    "        max_value, best_col, max_splited = choose_best_col(input_data[columns], self.label)\n",
    "        if not best_col:\n",
    "            node = Node(input_data[self.label].iloc[0])\n",
    "            parent_node.connect(parent_connection_label, node)\n",
    "            return \n",
    "        node = Node(best_col)\n",
    "        parent_node.connect(parent_connection_label, node)\n",
    "        new_columns = [col for col in columns if col!=best_col]\n",
    "        for splited_value, splited_data in max_splited.items():\n",
    "            self.construct(node, splited_value, splited_data, new_columns)\n",
    "\n",
    "    def construct_tree(self):\n",
    "        self.construct(self.root, \"\", self.data, self.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "\t()\n",
      "\t\toutlook\n",
      "\t\t\t(sunny)\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(overcast)\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(rainy)\n",
      "\t\t\t\twindy\n",
      "\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n"
     ]
    }
   ],
   "source": [
    "tree1 = ID3Tree(df,'play')\n",
    "tree1.construct_tree()\n",
    "tree1.print_tree(tree1.root, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"867pt\" height=\"671pt\"\n",
       " viewBox=\"0.00 0.00 867.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-667 863,-667 863,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M513.5,-663C513.5,-663 391.5,-663 391.5,-663 385.5,-663 379.5,-657 379.5,-651 379.5,-651 379.5,-592 379.5,-592 379.5,-586 385.5,-580 391.5,-580 391.5,-580 513.5,-580 513.5,-580 519.5,-580 525.5,-586 525.5,-592 525.5,-592 525.5,-651 525.5,-651 525.5,-657 519.5,-663 513.5,-663\"/>\n",
       "<text text-anchor=\"start\" x=\"387.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 0.8</text>\n",
       "<text text-anchor=\"start\" x=\"405\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.585</text>\n",
       "<text text-anchor=\"start\" x=\"407.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n",
       "<text text-anchor=\"start\" x=\"394.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"409\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M422,-536.5C422,-536.5 329,-536.5 329,-536.5 323,-536.5 317,-530.5 317,-524.5 317,-524.5 317,-480.5 317,-480.5 317,-474.5 323,-468.5 329,-468.5 329,-468.5 422,-468.5 422,-468.5 428,-468.5 434,-474.5 434,-480.5 434,-480.5 434,-524.5 434,-524.5 434,-530.5 428,-536.5 422,-536.5\"/>\n",
       "<text text-anchor=\"start\" x=\"335.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"334.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n",
       "<text text-anchor=\"start\" x=\"325\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"332\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M425.57,-579.58C418.46,-568.77 410.77,-557.09 403.6,-546.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"406.71,-544.55 398.29,-538.13 400.86,-548.4 406.71,-544.55\"/>\n",
       "<text text-anchor=\"middle\" x=\"392.41\" y=\"-557.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M594.5,-544C594.5,-544 464.5,-544 464.5,-544 458.5,-544 452.5,-538 452.5,-532 452.5,-532 452.5,-473 452.5,-473 452.5,-467 458.5,-461 464.5,-461 464.5,-461 594.5,-461 594.5,-461 600.5,-461 606.5,-467 606.5,-473 606.5,-473 606.5,-532 606.5,-532 606.5,-538 600.5,-544 594.5,-544\"/>\n",
       "<text text-anchor=\"start\" x=\"460.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\n",
       "<text text-anchor=\"start\" x=\"489.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n",
       "<text text-anchor=\"start\" x=\"484.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n",
       "<text text-anchor=\"start\" x=\"475\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"477\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M479.43,-579.58C484.91,-571.25 490.74,-562.39 496.41,-553.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"499.31,-555.74 501.88,-545.46 493.46,-551.89 499.31,-555.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"507.76\" y=\"-564.99\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#4de88e\" stroke=\"black\" d=\"M484,-425C484,-425 349,-425 349,-425 343,-425 337,-419 337,-413 337,-413 337,-354 337,-354 337,-348 343,-342 349,-342 349,-342 484,-342 484,-342 490,-342 496,-348 496,-354 496,-354 496,-413 496,-413 496,-419 490,-425 484,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"345\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\n",
       "<text text-anchor=\"start\" x=\"369\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.445</text>\n",
       "<text text-anchor=\"start\" x=\"375.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n",
       "<text text-anchor=\"start\" x=\"366\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"364\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M489.98,-460.58C481.5,-451.8 472.46,-442.44 463.72,-433.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"466.32,-431.05 456.86,-426.29 461.29,-435.91 466.32,-431.05\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#843de6\" stroke=\"black\" d=\"M710,-425C710,-425 575,-425 575,-425 569,-425 563,-419 563,-413 563,-413 563,-354 563,-354 563,-348 569,-342 575,-342 575,-342 710,-342 710,-342 716,-342 722,-348 722,-354 722,-354 722,-413 722,-413 722,-419 716,-425 710,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"571\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.85</text>\n",
       "<text text-anchor=\"start\" x=\"595\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.151</text>\n",
       "<text text-anchor=\"start\" x=\"601.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"start\" x=\"592\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n",
       "<text text-anchor=\"start\" x=\"594\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M569.02,-460.58C577.5,-451.8 586.54,-442.44 595.28,-433.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"597.71,-435.91 602.14,-426.29 592.68,-431.05 597.71,-435.91\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#3de684\" stroke=\"black\" d=\"M260.5,-306C260.5,-306 130.5,-306 130.5,-306 124.5,-306 118.5,-300 118.5,-294 118.5,-294 118.5,-235 118.5,-235 118.5,-229 124.5,-223 130.5,-223 130.5,-223 260.5,-223 260.5,-223 266.5,-223 272.5,-229 272.5,-235 272.5,-235 272.5,-294 272.5,-294 272.5,-300 266.5,-306 260.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"126.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.65</text>\n",
       "<text text-anchor=\"start\" x=\"148\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.146</text>\n",
       "<text text-anchor=\"start\" x=\"154.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n",
       "<text text-anchor=\"start\" x=\"145\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M339.2,-341.58C320.95,-331.92 301.37,-321.55 282.71,-311.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.56,-308.69 274.09,-307.11 281.29,-314.88 284.56,-308.69\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#c09cf2\" stroke=\"black\" d=\"M481.5,-306C481.5,-306 351.5,-306 351.5,-306 345.5,-306 339.5,-300 339.5,-294 339.5,-294 339.5,-235 339.5,-235 339.5,-229 345.5,-223 351.5,-223 351.5,-223 481.5,-223 481.5,-223 487.5,-223 493.5,-229 493.5,-235 493.5,-235 493.5,-294 493.5,-294 493.5,-300 487.5,-306 481.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"347.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.55</text>\n",
       "<text text-anchor=\"start\" x=\"369\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n",
       "<text text-anchor=\"start\" x=\"379\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"369.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"368\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M416.5,-341.58C416.5,-333.79 416.5,-325.53 416.5,-317.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"420,-317.71 416.5,-307.71 413,-317.71 420,-317.71\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M109,-179.5C109,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 109,-111.5 109,-111.5 115,-111.5 121,-117.5 121,-123.5 121,-123.5 121,-167.5 121,-167.5 121,-173.5 115,-179.5 109,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"20.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 47</text>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.28,-222.58C135.06,-211.12 120.69,-198.67 107.48,-187.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.99,-184.76 100.14,-180.85 105.4,-190.05 109.99,-184.76\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M240,-179.5C240,-179.5 151,-179.5 151,-179.5 145,-179.5 139,-173.5 139,-167.5 139,-167.5 139,-123.5 139,-123.5 139,-117.5 145,-111.5 151,-111.5 151,-111.5 240,-111.5 240,-111.5 246,-111.5 252,-117.5 252,-123.5 252,-123.5 252,-167.5 252,-167.5 252,-173.5 246,-179.5 240,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"155.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"158\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"148.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"147\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.5,-222.58C195.5,-212.43 195.5,-201.5 195.5,-191.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199,-191.37 195.5,-181.37 192,-191.37 199,-191.37\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M371,-179.5C371,-179.5 282,-179.5 282,-179.5 276,-179.5 270,-173.5 270,-167.5 270,-167.5 270,-123.5 270,-123.5 270,-117.5 276,-111.5 282,-111.5 282,-111.5 371,-111.5 371,-111.5 377,-111.5 383,-117.5 383,-123.5 383,-123.5 383,-167.5 383,-167.5 383,-173.5 377,-179.5 371,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"286.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"289\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"279.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\n",
       "<text text-anchor=\"start\" x=\"278\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M385.02,-222.58C376.63,-211.66 367.54,-199.85 359.09,-188.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.96,-186.85 353.09,-181.06 356.41,-191.12 361.96,-186.85\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#9cf2c0\" stroke=\"black\" d=\"M551.5,-187C551.5,-187 413.5,-187 413.5,-187 407.5,-187 401.5,-181 401.5,-175 401.5,-175 401.5,-116 401.5,-116 401.5,-110 407.5,-104 413.5,-104 413.5,-104 551.5,-104 551.5,-104 557.5,-104 563.5,-110 563.5,-116 563.5,-116 563.5,-175 563.5,-175 563.5,-181 557.5,-187 551.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"409.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 6.95</text>\n",
       "<text text-anchor=\"start\" x=\"435\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n",
       "<text text-anchor=\"start\" x=\"445\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"435.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"430\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M439.58,-222.58C444.23,-214.34 449.17,-205.58 453.98,-197.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"456.93,-198.95 458.8,-188.52 450.84,-195.51 456.93,-198.95\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M463,-68C463,-68 366,-68 366,-68 360,-68 354,-62 354,-56 354,-56 354,-12 354,-12 354,-6 360,0 366,0 366,0 463,0 463,0 469,0 475,-6 475,-12 475,-12 475,-56 475,-56 475,-62 469,-68 463,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"374.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"377\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"367.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"362\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.18,-103.73C451.97,-95.34 446.47,-86.47 441.21,-78.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"444.23,-76.23 435.98,-69.59 438.28,-79.93 444.23,-76.23\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M594,-68C594,-68 505,-68 505,-68 499,-68 493,-62 493,-56 493,-56 493,-12 493,-12 493,-6 499,0 505,0 505,0 594,0 594,0 600,0 606,-6 606,-12 606,-12 606,-56 606,-56 606,-62 600,-68 594,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"509.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"512\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"502.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"501\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M507.45,-103.73C512.58,-95.34 518,-86.47 523.19,-78.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"526.1,-79.95 528.33,-69.59 520.13,-76.29 526.1,-79.95\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#c09cf2\" stroke=\"black\" d=\"M711.5,-306C711.5,-306 573.5,-306 573.5,-306 567.5,-306 561.5,-300 561.5,-294 561.5,-294 561.5,-235 561.5,-235 561.5,-229 567.5,-223 573.5,-223 573.5,-223 711.5,-223 711.5,-223 717.5,-223 723.5,-229 723.5,-235 723.5,-235 723.5,-294 723.5,-294 723.5,-300 717.5,-306 711.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"569.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 5.95</text>\n",
       "<text text-anchor=\"start\" x=\"595\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\n",
       "<text text-anchor=\"start\" x=\"605\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"595.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"594\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M642.5,-341.58C642.5,-333.79 642.5,-325.53 642.5,-317.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"646,-317.71 642.5,-307.71 639,-317.71 646,-317.71\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M847,-298.5C847,-298.5 754,-298.5 754,-298.5 748,-298.5 742,-292.5 742,-286.5 742,-286.5 742,-242.5 742,-242.5 742,-236.5 748,-230.5 754,-230.5 754,-230.5 847,-230.5 847,-230.5 853,-230.5 859,-236.5 859,-242.5 859,-242.5 859,-286.5 859,-286.5 859,-292.5 853,-298.5 847,-298.5\"/>\n",
       "<text text-anchor=\"start\" x=\"760.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"759.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\n",
       "<text text-anchor=\"start\" x=\"750\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 43]</text>\n",
       "<text text-anchor=\"start\" x=\"752\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>12&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M697.76,-341.58C713.53,-329.9 730.69,-317.19 746.39,-305.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"748.28,-308.53 754.23,-299.76 744.11,-302.9 748.28,-308.53\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M691,-179.5C691,-179.5 594,-179.5 594,-179.5 588,-179.5 582,-173.5 582,-167.5 582,-167.5 582,-123.5 582,-123.5 582,-117.5 588,-111.5 594,-111.5 594,-111.5 691,-111.5 691,-111.5 697,-111.5 703,-117.5 703,-123.5 703,-123.5 703,-167.5 703,-167.5 703,-173.5 697,-179.5 691,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"602.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"605\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"595.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"590\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M642.5,-222.58C642.5,-212.43 642.5,-201.5 642.5,-191.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"646,-191.37 642.5,-181.37 639,-191.37 646,-191.37\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M822,-179.5C822,-179.5 733,-179.5 733,-179.5 727,-179.5 721,-173.5 721,-167.5 721,-167.5 721,-123.5 721,-123.5 721,-117.5 727,-111.5 733,-111.5 733,-111.5 822,-111.5 822,-111.5 828,-111.5 834,-117.5 834,-123.5 834,-123.5 834,-167.5 834,-167.5 834,-173.5 828,-179.5 822,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"737.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"740\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"730.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"729\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M689.72,-222.58C702.94,-211.12 717.31,-198.67 730.52,-187.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"732.6,-190.05 737.86,-180.85 728.01,-184.76 732.6,-190.05\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x16a4d9eb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('iris')\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, \n",
    "                                out_file=None,\n",
    "                                feature_names=iris.feature_names,\n",
    "                                class_names=iris.target_names,\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                special_characters=True)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 CART\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义二叉特征分裂函数\n",
    "def feature_split(X, feature_i, threshold):\n",
    "    split_func = None\n",
    "    if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "        split_func = lambda sample: sample[feature_i] >= threshold\n",
    "    else:\n",
    "        split_func = lambda sample: sample[feature_i] == threshold\n",
    "\n",
    "    X_left = np.array([sample for sample in X if split_func(sample)])\n",
    "    X_right = np.array([sample for sample in X if not split_func(sample)])\n",
    "\n",
    "    return np.array([X_left, X_right])\n",
    "\n",
    "\n",
    "### 计算基尼指数\n",
    "def calculate_gini(y):\n",
    "    # 将数组转化为列表\n",
    "    y = y.tolist()\n",
    "    probs = [y.count(i)/len(y) for i in np.unique(y)]\n",
    "    gini = sum([p*(1-p) for p in probs])\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "    def __init__(self, \n",
    "                 feature_i=None,\n",
    "                 threshold=None,\n",
    "                 leaf_value=None,\n",
    "                 left_branch=None,\n",
    "                 right_branch=None):\n",
    "        \n",
    "        self.feature_i = feature_i        # 特征索引\n",
    "        self.threshold = threshold        # 特征划分threshold\n",
    "        self.leaf_value = leaf_value      # 叶子结点取值\n",
    "        self.left_branch = left_branch    # 左子树\n",
    "        self.right_branch = right_branch  # 右子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDecisionTree():\n",
    "    '''\n",
    "    二叉决策树\n",
    "    '''\n",
    "    def __init__(self, min_sample_split=2, min_gini_impurity=999,\n",
    "                 max_depth=float('inf'), loss=None):\n",
    "        self.root = None\n",
    "        self.min_sample_split = min_sample_split    # node最小分裂数，默认为2\n",
    "        self.mini_gini_impurity = min_gini_impurity # node初始化gini不纯度\n",
    "        self.max_depth = max_depth                  # 二叉树最大深度\n",
    "        self.gini_impurity_calculation = None       # 基尼不纯度计算函数\n",
    "        self._leaf_value_calculation = None         # 叶子结点预测函数\n",
    "        self.loss = loss                            # 损失函数\n",
    "\n",
    "    ### 拟合函数\n",
    "    def fit(self, X, y, loss = None):\n",
    "        # 递归构建\n",
    "        self.root = self._build_tree(X,y)\n",
    "        self.loss = None\n",
    "\n",
    "    ### 决策树构建\n",
    "    def _build_tree(self, X, y, current_depth=0):\n",
    "        # 初始化最小基尼不纯度\n",
    "        init_gini_impurity = 999\n",
    "        # 初始化最佳特征索引和阈值\n",
    "        best_criteria = None\n",
    "        # 初始化数据子集\n",
    "        best_sets = None\n",
    "\n",
    "        # 合并输入和标签\n",
    "        Xy = np.concatenate((X,y), axis=1)\n",
    "        # 获取样本数和特征数\n",
    "        n_samples, n_features = X.shape\n",
    "        # 设定决策树构建条件\n",
    "        # 训练样本数量大于node的最小分裂样本数且当前tree的深度小于最大深度\n",
    "        if n_samples >= self.min_sample_split and current_depth <= self.max_depth:\n",
    "            # 遍历计算每个特征的gini impurity\n",
    "            for feature_i in range(n_features):\n",
    "                # 获取i特征的所有取值\n",
    "                feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "                # 获取i特征的唯一取值\n",
    "                unique_values = np.unique(feature_values)\n",
    "\n",
    "                # 遍历取值并寻找最佳特征分裂阈值\n",
    "                for threshold in unique_values:\n",
    "                    # 特征node二叉分裂\n",
    "                    Xy1, Xy2 = feature_split(Xy, feature_i, threshold)\n",
    "                    # 如果分裂后的子集大小都不为0\n",
    "                    if len(Xy1) >0 and len(Xy2) > 0:\n",
    "                        # 获取两个子集的标签\n",
    "                        y1 = Xy1[:, n_features:]\n",
    "                        y2 = Xy2[:, n_features:]\n",
    "\n",
    "                        # 计算gini impurity\n",
    "                        impurity = self.impurity_calculation(y, y1, y2)\n",
    "\n",
    "                        # 获取最小gini impurity\n",
    "                        # 最佳特征索引和分类阈值\n",
    "                        if impurity < init_gini_impurity:\n",
    "                            init_gini_impurity = impurity\n",
    "                            best_criteria = {'feature_i': feature_i, 'threshold': threshold}\n",
    "                            best_sets = {\n",
    "                                'leftX': Xy1[:, :n_features],\n",
    "                                'lefty': Xy1[:,n_features:],\n",
    "                                'rightX': Xy2[:, :n_features],\n",
    "                                'righty': Xy2[:, n_features:]\n",
    "                            }\n",
    "        # 如果小于当前的最小不纯度\n",
    "        if init_gini_impurity < self.mini_gini_impurity:\n",
    "            # 构建左右子树\n",
    "            left_branch = self._build_tree(best_sets[\"leftX\"], best_sets['lefty'], current_depth+1)\n",
    "            right_branch = self._build_tree(best_sets['rightX'], best_sets['righty'], current_depth+1)\n",
    "\n",
    "            return TreeNode(feature_i=best_criteria['feature_i'], threshold=best_criteria['threshold'],\n",
    "                            left_branch=left_branch, right_branch=right_branch)\n",
    "        \n",
    "        # 计算叶子取值\n",
    "        leaf_value = self._leaf_value_calculation(y)\n",
    "        return TreeNode(leaf_value=leaf_value)\n",
    "    \n",
    "\n",
    "    ### 二叉树值预测函数\n",
    "    def predict_value(self, x, tree=None):\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "        # 如果叶子结点已有值，则直接返回已有值\n",
    "        if tree.leaf_value is not None:\n",
    "            return tree.leaf_value\n",
    "        \n",
    "        # 选择特征并获取特征值\n",
    "        feature_value = x[tree.feature_i]\n",
    "\n",
    "        # 判断落入左子树还是右子树\n",
    "        branch = tree.right_branch\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            if feature_value >= tree.threshold:\n",
    "                branch = tree.left_branch\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.left_branch\n",
    "\n",
    "        # 测试子集\n",
    "        return self.predict_value(x, branch)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = [self.predict_value(sample) for sample in X]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 CART regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree(BinaryDecisionTree):\n",
    "    def _calculate_variance_reduction(self, y, y1, y2):\n",
    "        var_tot = np.var(y, axis=0)\n",
    "        var_y1 = np.var(y1, axis=0)\n",
    "        var_y2 = np.var(y2,axis=0)\n",
    "        frac_1 = len(y1)/len(y)\n",
    "        frac_2 = len(y2)/len(y)\n",
    "        # 计算方差减少量\n",
    "        variance_reduction = var_tot - (frac_1*var_y1 + frac_2*var_y2)\n",
    "\n",
    "        return sum(variance_reduction)\n",
    "    \n",
    "    # node值取平均\n",
    "    def _mean_of_y(self, y):\n",
    "        value = np.mean(y, axis=0)\n",
    "        return value if len(value)>1 else value[0]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.impurity_calculation = self._calculate_variance_reduction\n",
    "        self._leaf_value_calculation = self._mean_of_y\n",
    "        super(RegressionTree, self).fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 CART Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTree(BinaryDecisionTree):\n",
    "    def _calculate_gini_impurity(self, y, y1, y2):\n",
    "        p = len(y1)/len(y2)\n",
    "        gini = calculate_gini(y)\n",
    "        gini_impurity = p*calculate_gini(y1) + (1-p)*calculate_gini(y2)\n",
    "        return gini_impurity\n",
    "    \n",
    "    def _majority_vote(self, y):\n",
    "        most_common = None\n",
    "        max_count = 0\n",
    "        for label in np.unique(y):\n",
    "            # 统计数量多的\n",
    "            count = len(y[y==label])\n",
    "            if count > max_count:\n",
    "                most_common = label\n",
    "                max_count = count\n",
    "        return most_common\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.impurity_calculation = self._calculate_gini_impurity\n",
    "        self._leaf_value_calculation = self._majority_vote\n",
    "        super(ClassificationTree, self).fit(X,y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l3/gdxbk2l908b4jq5bhgm39cl00000gn/T/ipykernel_88093/2521257058.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([X_left, X_right])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.load_iris()\n",
    "X, y = data.data, data.target\n",
    "# 注意！是否要对y进行reshape取决于numpy版本\n",
    "y = y.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "clf = ClassificationTree()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l3/gdxbk2l908b4jq5bhgm39cl00000gn/T/ipykernel_88093/2521257058.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([X_left, X_right])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5850.994726399332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "y = y.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "model = RegressionTree()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6345.796992481203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fit5221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
